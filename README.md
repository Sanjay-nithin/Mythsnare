# ğŸ§  MythSnare â€” Misinformation Detection with Real-Time Voice Intelligence

**MythSnare** is an intelligent, voice-enabled platform that detects misinformation using live transcription, AI-powered fact-checking, and real-time interaction. It distinguishes between factual statements and regional news, offering users a chatbot-style experience to verify claims from various media inputs â€” including speech, text, and files.

---

## âœ¨ Features

- ğŸ™ï¸ **Voice Assistant**: Speak directly to MythSnare â€” it transcribes and responds in real time.
- ğŸ”Š **Live Transcription**: Converts live speech to text instantly via WebSockets and Whisper/SpeechRecognition.
- ğŸ“‚ **Multimedia Support**: Upload audio/video/text for automatic transcription and fact-checking.
- ğŸ§  **Misinformation Detection**:
  - Factual statements: Verified using an LLM (e.g., GPT).
  - Regional news: Cross-referenced with RSS feeds and real-time scraping.
- ğŸŒ **Multilingual Input**: Accepts and transcribes speech in multiple languages.
- ğŸ’¬ **Chatbot Interface**: Intuitive UI for seamless conversation with AI.
  
---

## ğŸ› ï¸ Tech Stack

### ğŸ”§ Backend
- **Django** (core framework)
- **Django Channels** (WebSockets for real-time transcription)
- **Whisper / Whisper.cpp** (audio transcription)
- **SpeechRecognition** (Google API for lightweight live transcription)
- **Custom NLP Models** (for text classification)

### ğŸ’» Frontend
- **Chatbot UI** with file upload and live transcription streaming

### ğŸ” Fact Checking
- **OpenAI GPT / LLM APIs**
- **RSS Feed Parsing + Scraping** (for regional news verification)

---

## ğŸš€ Installation & Setup

### 1. Clone the Repo

```bash
git clone https://github.com/Sanjay-nithin/Mythsnare.git
cd Mythsnare
```

### 2. Create a Virtual Environment (Optional)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. API Key Setup

To use MythSnare's fact-checking capabilities via OpenRouter (LLM API), you'll need to create an API key:

#### 1. Sign Up & Create API Key
- Visit [Open Router](https://openrouter.ai/keys)
- Sign in with your account (GitHub, Google, etc.)
- Click "Create Key" and copy the generated API key (e.g., `sk-xxxxxxxxxxxxxxxxxxxxx`)

#### 2. Paste the key 

In 'templates/' directory there is a .env file paste the key
```bash
OPEN_ROUTER_API_KEY=YOUR OPEN ROUTER KEY
```



### 5. Run the app
```bash
daphne truthtell.asgi:application
```

## ğŸ“‚ Project Structure
```bash
Mythsnare/
â”‚
â”œâ”€â”€ media/                   # Sample data to upload
â”œâ”€â”€ results/checkpoint-500/  # Results of the classification model
â”œâ”€â”€ trained_model/           # Custom trained classification model
â”œâ”€â”€ transcribe/              # Contains the app's logic
â”‚   â”‚
â”‚   â””â”€â”€templates/            # Frontend html,css, javascript files
â”œâ”€â”€ truthtell                # Django's main project 
â””â”€â”€ requirements.txt         # Dependencies
  
```

## Future Enhancements
-Voice feedback
-Support for fake image/video detection
-Deep fake audio warnings


